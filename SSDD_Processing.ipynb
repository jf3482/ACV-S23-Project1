{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-5MojmoX8RA"
   },
   "source": [
    "# Preparing the dataset.\n",
    "1) Extraction of the various files\n",
    "\n",
    "\n",
    "2) Converting the data into format readable by Detectron2\n",
    "\n",
    "\n",
    "3) Splitting the data up into training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XTYtuc3c4xm"
   },
   "source": [
    "## Import and linking to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10148,
     "status": "ok",
     "timestamp": 1677387561162,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "HiYE_V1N5uLt",
    "outputId": "007641ba-9f60-46e1-bab3-bdec39333f02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.8/dist-packages (5.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-ir6nf77m\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-ir6nf77m\n",
      "  Resolved https://github.com/facebookresearch/detectron2.git to commit 38af375052d3ae7331141bc1a22cfa2713b02987\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (7.1.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (3.2.2)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (2.0.6)\n",
      "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (2.2.0)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (0.1.8)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (0.8.10)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (2.2.1)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (4.64.1)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (2.11.2)\n",
      "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
      "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (0.1.9)\n",
      "Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (2.3.0)\n",
      "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (1.3.2)\n",
      "Requirement already satisfied: black in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (23.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.21.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (5.1)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core>=1.1->detectron2==0.6) (5.10.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.8/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2==0.6) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2==0.6) (1.4.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.8/dist-packages (from black->detectron2==0.6) (8.1.3)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black->detectron2==0.6) (3.0.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from black->detectron2==0.6) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from black->detectron2==0.6) (4.4.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.8/dist-packages (from black->detectron2==0.6) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (3.19.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (0.38.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (57.4.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (2.25.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (1.51.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (1.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (2.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (1.15.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.6) (6.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.24.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (4.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2==0.6) (3.12.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pyyaml==5.1\n",
    "import sys, os, distutils.core\n",
    "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities.\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
    "#!git clone 'https://github.com/facebookresearch/detectron2'\n",
    "#dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "#!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "#sys.path.insert(0, os.path.abspath('./detectron2'))\n",
    "\n",
    "# Properly install detectron2. (Please do not install twice in both ways)\n",
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1448,
     "status": "ok",
     "timestamp": 1677387564698,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "uaOghvRp5yGo",
    "outputId": "b978eb8a-9fe1-4954-ae6c-ecf0fd23d2d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_Mar__8_18:18:20_PST_2022\n",
      "Cuda compilation tools, release 11.6, V11.6.124\n",
      "Build cuda_11.6.r11.6/compiler.31057947_0\n",
      "torch:  1.13 ; cuda:  cu116\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2274,
     "status": "ok",
     "timestamp": 1677387566968,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "XHVKcUyUYWFo"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from detectron2.structures import BoxMode \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1677387566969,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "RiwNlsUCrPIw"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "\n",
    "#Mounting google drive to retrieve outcomes\n",
    "#drive.mount('/content/drive/')\n",
    "#Change to your own directory\n",
    "#os.chdir('/content/drive/My Drive/Colab Notebooks/AppliedCV/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34962,
     "status": "ok",
     "timestamp": 1677387601924,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "MdIFfjjfFbGb",
    "outputId": "f2a05cc1-074d-41ce-dc59-3cdad79f32bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "google-drive-ocamlfuse is already the newest version (0.7.30-0ubuntu1~ubuntu20.04.1).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-510\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
      " Mount Google Drive on Ubuntu (via FUSE)\n",
      " More info: https://launchpad.net/~alessandro-strada/+archive/ubuntu/ppa\n",
      "Press [ENTER] to continue or Ctrl-c to cancel adding it.\n",
      "\n",
      "Hit:1 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Hit:5 http://ppa.launchpad.net/alessandro-strada/ppa/ubuntu focal InRelease\n",
      "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
      "Hit:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
      "Hit:10 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
      "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
      "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
      "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
      "Hit:15 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
      "Fetched 336 kB in 1s (288 kB/s)\n",
      "Reading package lists... Done\n",
      "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Hit:6 http://ppa.launchpad.net/alessandro-strada/ppa/ubuntu focal InRelease\n",
      "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
      "Hit:10 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
      "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
      "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
      "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
      "Hit:15 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
      "Fetched 222 kB in 1s (191 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "google-drive-ocamlfuse is already the newest version (0.7.30-0ubuntu1~ubuntu20.04.1).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-510\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install google-drive-ocamlfuse\n",
    "!sudo add-apt-repository ppa:alessandro-strada/ppa\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install google-drive-ocamlfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1677387641954,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "oqBsSZGtFigi"
   },
   "outputs": [],
   "source": [
    "!google-drive-ocamlfuse -headless -id=**Insert id here** -secret=**Insert secret here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1551,
     "status": "ok",
     "timestamp": 1677387646129,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "Z_WnM63yFo9c",
    "outputId": "10be33af-41cd-4f7b-c0ea-8e577aa31cae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuse: mountpoint is not empty\n",
      "fuse: if you are sure this is safe, use the 'nonempty' mount option\n"
     ]
    }
   ],
   "source": [
    "#Initializing google drive to a folder\n",
    "if not os.path.exists(\"./acv\"):\n",
    "  os.makedirs(\"./acv\")\n",
    "\n",
    "!google-drive-ocamlfuse acv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 165,
     "status": "ok",
     "timestamp": 1677387686111,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "sYJDfskRFii2"
   },
   "outputs": [],
   "source": [
    "os.chdir('./acv/Colab Notebooks/AppliedCV/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11xVD14hd2K9"
   },
   "source": [
    "## Extraction of various files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1677387692860,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "s75RjEJlrkiu"
   },
   "outputs": [],
   "source": [
    "#Initialization\n",
    "root = './Dataset/SSDD/'\n",
    "xml_path = root + 'Annotations_sub/'\n",
    "jpg_test = root + 'JPEGImages_sub_test/'\n",
    "jpg_train = root + 'JPEGImages_sub_train/'\n",
    "dest = root + 'Proc_data/'\n",
    "imagesets = root + 'Images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2730,
     "status": "ok",
     "timestamp": 1677387697994,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "Kg4N93eAPN0V"
   },
   "outputs": [],
   "source": [
    "#Create a new directory because it does not exist\n",
    "if not os.path.exists(dest):\n",
    "  os.makedirs(dest)\n",
    "if not os.path.exists(dest + \"train/\"):\n",
    "  os.makedirs(dest + \"train/\")\n",
    "if not os.path.exists(dest + \"test/\"):\n",
    "  os.makedirs(dest + \"test/\")\n",
    "if not os.path.exists(dest + \"test_offshore/\"):\n",
    "  os.makedirs(dest + \"test_offshore/\")\n",
    "if not os.path.exists(dest + \"test_inshore/\"):\n",
    "  os.makedirs(dest + \"test_inshore/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 3348,
     "status": "ok",
     "timestamp": 1677387701691,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "-emL8dpiPN3A"
   },
   "outputs": [],
   "source": [
    "#Reading csv files into DataFrame.\n",
    "test = pd.read_csv(imagesets + 'test.txt', header = None, names = ['file'])\n",
    "train = pd.read_csv(imagesets + 'train.txt', header = None, names = ['file'])\n",
    "test_offshore = pd.read_csv(imagesets + 'test_offshore.txt', header = None, names = ['file'])\n",
    "test_inshore = pd.read_csv(imagesets + 'test_inshore.txt', header = None, names = ['file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677387701691,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "HHjhnYC2PN5o"
   },
   "outputs": [],
   "source": [
    "#Function that copies files from given JPEG folders to the dataset folder\n",
    "def copyFiles(df, orig = None, dest = None):\n",
    "  i = 0\n",
    "  for index, rows in df.iterrows():\n",
    "    i += 1\n",
    "    if i % 500 == 0:\n",
    "            print (i)\n",
    "    shutil.copyfile(orig + rows['file'] + '.jpg',\n",
    "                    dest + rows['file'] + '.jpg')  \n",
    "  print(\"Moved \" + str(i) + \" files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "executionInfo": {
     "elapsed": 425837,
     "status": "error",
     "timestamp": 1677388130860,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "rvDhdlObPN8T",
    "outputId": "8d7d336b-cb1b-425b-ad65-9cda35196ae2"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-633cb64ec3a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Sorting out files by moving them to the correct dataset path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#copyFiles(test, jpg_test, dest + 'test/')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcopyFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjpg_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcopyFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_offshore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjpg_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'test_offshore/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcopyFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inshore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjpg_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'test_inshore/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-9157c8fc26cf>\u001b[0m in \u001b[0;36mcopyFiles\u001b[0;34m(df, orig, dest)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     shutil.copyfile(orig + rows['file'] + '.jpg',\n\u001b[0m\u001b[1;32m      9\u001b[0m                     dest + rows['file'] + '.jpg')  \n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Moved \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" files.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                     \u001b[0m_fastcopy_sendfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0m_GiveupOnFastCopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Sorting out files by moving them to the correct dataset path\n",
    "#copyFiles(test, jpg_test, dest + 'test/')\n",
    "copyFiles(train, jpg_train, dest + 'train/')\n",
    "copyFiles(test_offshore, jpg_test, dest + 'test_offshore/')\n",
    "copyFiles(test_inshore, jpg_test, dest + 'test_inshore/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1677387303679,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "9nM5RZHlPN_L"
   },
   "outputs": [],
   "source": [
    "#Function that extracts ground truth information from xml file \n",
    "def extract_xml(path):\n",
    "  \"\"\"Returns a pandas dataframe containing information from xml files in path\"\"\"\n",
    "  xml_list = []\n",
    "  for xml_file in glob.glob(path):\n",
    "      tree = ET.parse(xml_file)\n",
    "      root = tree.getroot()\n",
    "      for member in root.findall('object'):\n",
    "          value = (root.find('filename').text,\n",
    "                    int(root.find('size')[0].text),\n",
    "                    int(root.find('size')[1].text),\n",
    "                    member[0].text,\n",
    "                    int(member[4][0].text),\n",
    "                    int(member[4][1].text),\n",
    "                    int(member[4][2].text),\n",
    "                    int(member[4][3].text)\n",
    "                    )\n",
    "          xml_list.append(value)\n",
    "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "  xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "  return xml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1677387303679,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "-31S2WzJPOBe"
   },
   "outputs": [],
   "source": [
    "labels_df = extract_xml(xml_path + '*.xml')\n",
    "labels_df.to_csv((root + 'labels.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQOPc32feLUc"
   },
   "source": [
    "## Converting the data into format readable by Detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1677387303680,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "jFa-oBaxPOD-"
   },
   "outputs": [],
   "source": [
    "#Convert annotations into Detectron's format\n",
    "def standardize(path, annotations, df, grouped):\n",
    "  anns_id = [i.split('.')[0] for i in annotations]\n",
    "  anns_df = pd.DataFrame(anns_id, columns=['file'])\n",
    "\n",
    "  # Attach correct image file path\n",
    "  anns_df = df.merge(df, \n",
    "                     on = 'file',  \n",
    "                     how = 'inner')\n",
    "  \n",
    "  # Give default values\n",
    "  std = {i: {\n",
    "        \"file_name\": df.loc[df['file'] == i]['type'].values[0] + i +'.jpg',\n",
    "        \"height\": 800, # All images of the same dimension\n",
    "        \"width\": 800, # All images of the same dimension\n",
    "        \"image_id\": i,\n",
    "        \"annotations\": []\n",
    "        } for i in df['file'].values\n",
    "      }\n",
    "  \n",
    "  # Overwrite files with correct annotations\n",
    "  keys = grouped.groups.keys()\n",
    "  for i in keys:\n",
    "    if i.split('.')[0] in std:\n",
    "      j = grouped.get_group(i)\n",
    "      temp = []\n",
    "      for index, row in j.iterrows():\n",
    "        ann_temp = {\n",
    "            'bbox': [\n",
    "                      row['xmin'],\n",
    "                      row['ymin'],\n",
    "                      row['xmax'],\n",
    "                      row['ymax']\n",
    "                    ],\n",
    "            'bbox_mode': BoxMode.XYXY_ABS,\n",
    "            'category_id': 0\n",
    "            }\n",
    "        temp.append(ann_temp)\n",
    "      std[i.split('.')[0]]['annotations'] = temp\n",
    "  \n",
    "  # Cache\n",
    "  f = open(path + \"standardDict.pkl\", \"wb\")  # the \"wb\" mode opens the file in binary format for writing\n",
    "  pickle.dump(list(std.values()), f)\n",
    "  f.close()\n",
    "  \n",
    "  return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1677387303680,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "_MR5m9gNPOGm"
   },
   "outputs": [],
   "source": [
    "# Add path to datasets\n",
    "test['type'] = dest + 'test/'\n",
    "train['type'] = dest + 'train/'\n",
    "test_offshore['type'] = dest + 'test_offshore/'\n",
    "test_inshore['type'] = dest + 'test_inshore/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1677387303680,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "sK_gVog6POJD"
   },
   "outputs": [],
   "source": [
    "# Make standardized annotations\n",
    "anns = os.listdir(xml_path)\n",
    "grouped = labels_df.groupby('filename') # used later\n",
    "test_std = standardize(dest + 'test/', anns, test, grouped)\n",
    "train_std = standardize(dest + 'train/', anns, train, grouped)\n",
    "test_o_std = standardize(dest + 'test_offshore/', anns, test_offshore, grouped)\n",
    "test_i_std = standardize(dest + 'test_inshore/', anns, test_inshore, grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1677387303680,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "XpB6lBVvPOLn"
   },
   "outputs": [],
   "source": [
    "# Function that retrieves a standard dataset compatible with detectron2\n",
    "def get_dict(type):\n",
    "  \"\"\" Returns a list[dict] containing information about the dataset \"\"\"\n",
    "  import pickle\n",
    "  root = dest + type + '/'\n",
    "  with open(root + \"standardDict.pkl\", \"rb\") as input_file:\n",
    "    return pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3t355eCWU8L"
   },
   "source": [
    "## Splitting the data up into training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1677387303681,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "vL3tq00mTRkM"
   },
   "outputs": [],
   "source": [
    "train = get_dict('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1677387303681,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "3FX26FO5TRm_"
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(train, train_size=0.8, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1677387303681,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "zlcTEh4gTRp1"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(dest + \"train/train/\"):\n",
    "  os.makedirs(dest + \"train/train/\")\n",
    "if not os.path.exists(dest + \"train/val/\"):\n",
    "  os.makedirs(dest + \"train/val/\")\n",
    "\n",
    "f = open(dest + 'train/train/' + \"standardDict.pkl\", \"wb\")\n",
    "pickle.dump(train_data, f)\n",
    "f.close()\n",
    "\n",
    "f = open(dest + 'train/val/' + \"standardDict.pkl\", \"wb\")\n",
    "pickle.dump(val_data, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1677387303681,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "jzT925qyTRsl"
   },
   "outputs": [],
   "source": [
    "#Prepare toy dataset for quick training/testing\n",
    "train_data, toy_data = train_test_split(train, train_size=0.99, random_state = 1)\n",
    "\n",
    "if not os.path.exists(dest + \"train/toy/\"):\n",
    "  os.makedirs(dest + \"train/toy/\")\n",
    "\n",
    "f = open(dest + 'train/toy/' + \"standardDict.pkl\", \"wb\") \n",
    "pickle.dump(toy_data, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1677387303681,
     "user": {
      "displayName": "Jit Soon Foo",
      "userId": "08801904773871791364"
     },
     "user_tz": 300
    },
    "id": "3gFjwh_3rku_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
